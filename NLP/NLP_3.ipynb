{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOW8PlAnG8/rxu5cojmLHJW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XcL67QiB-YI6"},"outputs":[],"source":["import re\n","import nltk\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer"]},{"cell_type":"code","source":["import spacy\n","nlp = spacy.load('en_core_web_sm')\n"],"metadata":{"id":"AEWl685l-ijg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('stopwords')\n","nltk.download('wordnet')"],"metadata":{"id":"zz-xmbod-lBE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = ['I love programming!', 'Python is amazing...', 'I enjoy solving problems.','i hate c#']\n","labels = ['positive', 'positive', 'positive', 'negative']"],"metadata":{"id":"XEG6iYfj-qMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()"],"metadata":{"id":"AfG6qxaw-q9W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def clean_text(text):\n","    text = re.sub(r'[^A-Za-z\\s]', '', text)\n","    text = text.lower()\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text\n","\n","data_cleaned = [clean_text(text) for text in data]"],"metadata":{"id":"Z5bNpwDp-s_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def lemmatize_text(text):\n","    words = text.split()\n","    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n","    return \" \".join(lemmatized_words)\n","\n","data_lemmatized = [lemmatize_text(text) for text in data_cleaned]"],"metadata":{"id":"nL1QIJCS-vTJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stop_words = set(stopwords.words('english'))\n","def remove_stop_words(text):\n","    words = text.split()\n","    words_filtered = [word for word in words if word not in stop_words]\n","    return \" \".join(words_filtered)\n","\n","data_no_stopwords = [remove_stop_words(text) for text in data_lemmatized]"],"metadata":{"id":"AHMW4DNZ-yDN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tfidf_vectorizer = TfidfVectorizer()\n","tfidf_matrix = tfidf_vectorizer.fit_transform(data_no_stopwords)"],"metadata":{"id":"CjFyMxA2-3q2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Cleaned and Lemmatized Text (no stopwords):\")\n","print(data_no_stopwords)\n","print()\n","print(\"TF-IDF Matrix Shape:\")\n","print(tfidf_matrix.shape)"],"metadata":{"id":"p6xnO37H-4VD"},"execution_count":null,"outputs":[]}]}
