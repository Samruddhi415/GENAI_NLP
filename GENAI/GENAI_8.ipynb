{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzn-bv550E_H"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchaudio transformers speechbrain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from speechbrain.pretrained import Tacotron2, HIFIGAN\n",
        "import torchaudio\n",
        "import IPython.display as ipd\n",
        "\n",
        "# Initialize Tacotron2 from Hugging Face\n",
        "tacotron2 = Tacotron2.from_hparams(source=\"speechbrain/tts-tacotron2-ljspeech\", savedir=\"tmpdir_tts\")\n",
        "\n",
        "# Define input text\n",
        "text = input(\"Enter text prompt:\")\n",
        "\n",
        "# Generate the Mel spectrogram using Tacotron2\n",
        "mel_output, mel_length, alignment = tacotron2.encode_text(text)\n",
        "\n",
        "# Load a pre-trained HiFi-GAN vocoder from Hugging Face\n",
        "hifi_gan = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-ljspeech\", savedir=\"tmpdir_vocoder\")\n",
        "\n",
        "# Convert Mel spectrogram to waveform using HiFi-GAN vocoder\n",
        "with torch.no_grad():  # Disable gradient calculation for inference\n",
        "    waveforms = hifi_gan.decode_batch(mel_output)\n",
        "\n",
        "# Save the audio output\n",
        "torchaudio.save('output_audio_hifigan.wav', waveforms.squeeze(1), 22050)\n",
        "\n",
        "# Play the audio\n",
        "ipd.Audio('output_audio_hifigan.wav')"
      ],
      "metadata": {
        "id": "AZFtnucY0Wph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}